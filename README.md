# Spiralmem: Local Video Memory System

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Node.js](https://img.shields.io/badge/Node.js-18%2B-green.svg)](https://nodejs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue.svg)](https://www.typescriptlang.org/)
[![Production Ready](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)]()

> **üöÄ INSTALL NOW**: 
> - **Unix/Linux/macOS**: `curl -fsSL https://raw.githubusercontent.com/spiralbewilder/spiralmem/master/install.sh | bash`
> - **Windows**: `iwr -useb https://raw.githubusercontent.com/spiralbewilder/spiralmem/master/install.ps1 | iex`

A privacy-first, local video memory system that transforms video files into searchable, organized memories using AI transcription and semantic search.

## üöÄ Quick Install

**One-Command Installation**:

**Unix/Linux/macOS:**
```bash
curl -fsSL https://raw.githubusercontent.com/spiralbewilder/spiralmem/master/install.sh | bash
```

**Windows (PowerShell):**
```powershell
iwr -useb https://raw.githubusercontent.com/spiralbewilder/spiralmem/master/install.ps1 | iex
```

**Alternative: Download & Run**:
```bash
# Unix/Linux/macOS
wget https://raw.githubusercontent.com/spiralbewilder/spiralmem/master/install.sh
chmod +x install.sh && bash install.sh

# Windows (PowerShell)
curl -O https://raw.githubusercontent.com/spiralbewilder/spiralmem/master/install.ps1
.\install.ps1
```

**‚Üí [üìñ Complete Getting Started Guide](GETTING_STARTED.md)** ‚Üê *Start here if you're new!*

Or install manually following the detailed instructions below ‚¨áÔ∏è

---

## üì¶ Manual Installation

### Prerequisites

**Required:**
- **Node.js** 18+ (LTS recommended)
- **Python** 3.8+ with pip
- **FFmpeg** 4.0+ (for video processing)

### Linux (Ubuntu/Debian)
```bash
# Install system dependencies
sudo apt update
sudo apt install nodejs npm python3 python3-pip ffmpeg sqlite3

# Install Python packages
pip3 install faster_whisper

# Clone and setup Spiralmem
git clone https://github.com/spiralbewilder/spiralmem.git
cd spiralmem
npm install
npm run build

# Test installation
npm run cli -- --help
```

### macOS
```bash
# Install dependencies via Homebrew
brew install node python ffmpeg

# Install Python packages
pip3 install faster_whisper

# Clone and setup Spiralmem
git clone https://github.com/spiralbewilder/spiralmem.git
cd spiralmem
npm install
npm run build

# Test installation
npm run cli -- --help
```

### Windows

**Option 1: PowerShell Installer (Recommended)**
```powershell
# Download and run PowerShell installer
iwr -useb https://raw.githubusercontent.com/spiralbewilder/spiralmem/master/install.ps1 | iex

# Or download first, then run
curl -O https://raw.githubusercontent.com/spiralbewilder/spiralmem/master/install.ps1
.\install.ps1
```

**Option 2: Manual Installation**
```powershell
# Install dependencies via Chocolatey or winget
choco install nodejs python ffmpeg
# or: winget install OpenJS.NodeJS Python.Python.3 Gyan.FFmpeg

# Install Python packages
pip install faster_whisper

# Clone and setup Spiralmem
git clone https://github.com/spiralbewilder/spiralmem.git
cd spiralmem
npm install
npm run build

# Test installation
npm run cli -- --help
```

### Verify Installation
```bash
# Quick check
npm run cli -- check

# Comprehensive test suite
./scripts/test-install.sh

# Should show all green checkmarks ‚úÖ
```

---

## ‚ö° Quick Start

### After Installation

**Step 1: Configure Environment (Optional)**
```bash
# Navigate to your installation directory
cd ~/.spiralmem  # or wherever spiralmem was installed

# Copy the environment template (this creates your personal configuration)
cp .env.example .env

# Edit configuration if needed (optional - system works without API keys)
nano .env  # or your preferred editor
```

> **üìù Note**: Environment configuration is **optional**. Spiralmem works perfectly without any API keys for local video processing. You only need to configure environment variables if you want advanced YouTube features.

**Step 2: Start Using Spiralmem**
```bash
# 1. Initialize the system
spiralmem init

# 2. Add your first video (supports local files and YouTube URLs!)
spiralmem add-video /path/to/your/video.mp4
spiralmem add-video https://youtu.be/your-video-url

# 3. Search your content
spiralmem search "your search terms"

# 4. View system statistics
spiralmem stats
```

### Environment Configuration Details

Spiralmem uses an optional environment file for advanced configuration. Here's what you need to know:

**üîß Required Steps:**
- ‚úÖ **None!** - The system works out-of-the-box without any configuration

**‚öôÔ∏è Optional Configuration:**
If you'd like to customize settings or enable advanced features:

1. **Create your personal configuration:**
   ```bash
   cp .env.example .env
   ```

2. **Available Configuration Options:**
   ```bash
   # YouTube API Key (optional - for advanced YouTube features only)
   # The system uses yt-dlp for YouTube downloads, so this is rarely needed
   YOUTUBE_API_KEY=your_api_key_here
   
   # Database location (optional - defaults work fine)
   SPIRALMEM_DB_PATH=./data/spiralmem.db
   
   # Logging level (optional - 'info' is recommended)
   SPIRALMEM_LOG_LEVEL=info
   
   # MCP Server (optional - enabled by default)
   SPIRALMEM_MCP_ENABLED=true
   ```

**üîë YouTube API Key Information:**
- **When you need it**: Only for advanced YouTube features (quotas, channel management)
- **When you don't**: For basic YouTube video processing (most users)
- **How to get one**: Visit [Google Cloud Console](https://console.developers.google.com/apis/credentials) and create a YouTube Data API v3 key
- **Privacy note**: Your API key stays local and is never transmitted anywhere

**üõ°Ô∏è Security Notice:**
Your `.env` file is automatically excluded from version control and stays private on your system. Never share your API keys with others.

---

## Overview

Spiralmem is a **production-ready** local video intelligence system that provides:

- **Privacy-First Processing**: All AI processing happens locally, no cloud dependencies
- **Video Intelligence**: Transform any video into searchable transcript memories
- **Organized Storage**: Space-based organization with powerful search capabilities
- **MCP Integration**: AI assistant integration via Model Context Protocol
- **Cross-Platform**: Works on Linux, macOS, and Windows
- **Extensible Architecture**: Database schema ready for platform video integration

## Key Features

- üîí **Complete Privacy**: All AI processing local, no external API calls
- üé• **Video Processing**: Extract audio, generate transcripts with faster_whisper
- üîç **Powerful Search**: Keyword search across video transcripts and content
- üóÇÔ∏è **Smart Organization**: Space-based memory organization system
- ü§ñ **AI Integration**: MCP server for Claude and other AI assistants
- ‚ö° **Fast Performance**: SQLite database with optimized queries
- üîß **Production Ready**: Complete error handling, logging, and monitoring

## Documentation

- **[System Design Specification](SYSTEM_DESIGN_SPECIFICATION.md)**: Complete technical architecture
- **[Logical Architecture](LOGICAL_ARCHITECTURE.md)**: Platform-independent rebuild blueprint
- **[Installer Design](INSTALLER_DESIGN.md)**: One-step installation strategy
- **[Next Steps Roadmap](NEXT_STEPS_ROADMAP.md)**: Strategic development plan

## All Commands

```bash
# System management
spiralmem init                           # Initialize system
spiralmem check                          # Health check
spiralmem stats                          # System statistics

# Content management  
spiralmem add-video path/to/video.mp4    # Add video
spiralmem search "query"                 # Search content
spiralmem spaces                         # List spaces
spiralmem create-space name              # Create space

# Data operations
spiralmem export data.json               # Export data
spiralmem config                         # Show config

# Server operations
spiralmem serve-mcp                      # Start MCP server
```

## System Architecture

### Current Tech Stack
- **Runtime**: Node.js 18+ with TypeScript
- **Database**: SQLite 3 with WAL mode and foreign key support
- **AI Processing**: faster_whisper (Python) for local transcription
- **Video Processing**: FFmpeg for audio extraction and metadata
- **Search**: Full-text search with planned semantic search extension
- **Protocol**: MCP (Model Context Protocol) for AI assistant integration

### Performance Characteristics
Based on 5-minute video (15MB) testing:
- **Video Processing**: ~20 seconds total (acceptable for background processing)
- **Search Performance**: <2ms for keyword searches across 1000+ memories
- **Memory Usage**: ~300MB during processing, ~100MB idle
- **Storage Overhead**: ~20% metadata overhead vs original content

## Current Status: Production Ready ‚úÖ

**Functional Components:**
- ‚úÖ Complete video processing pipeline (validation ‚Üí metadata ‚Üí audio ‚Üí transcription ‚Üí chunking ‚Üí storage)
- ‚úÖ Database architecture with migrations and foreign key integrity
- ‚úÖ Fast keyword search across video transcripts
- ‚úÖ Memory organization with spaces
- ‚úÖ MCP server integration for AI assistants
- ‚úÖ Error handling, logging, and recovery
- ‚úÖ Cross-platform compatibility (Linux, macOS, Windows)

**Verified Capabilities:**
- Process video files into searchable transcript memories
- Organize content in isolated spaces with proper permissions
- Search across all video content with relevance ranking
- Export and backup functionality
- Integration with Claude and other AI assistants via MCP

## Planned Enhancements

See **[NEXT_STEPS_ROADMAP.md](NEXT_STEPS_ROADMAP.md)** for the complete development roadmap including:

### Phase 1: Production Readiness (Next 2-4 weeks)
- One-step installer for all platforms
- Performance optimization (targeting <15s video processing)
- Enhanced error handling and robustness

### Phase 2: Core Feature Completion (1-2 months)
- Semantic search with vector embeddings
- YouTube integration (hybrid architecture)
- Advanced content management and batch processing

### Phase 3: User Interface (2-3 months)
- Web-based GUI with video playback
- Mobile companion app
- Real-time processing status and management interface

### Phase 4+: Advanced AI Features (3-12 months)
- Content summarization and speaker identification
- Multi-platform connectors (Spotify, Zoom, Teams)
- Collaboration features and team workspaces

## License

MIT License - see LICENSE file for details